{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference on Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Setup and Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we import the libraries needed for this program to work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Image processing and system libraries\n",
    "import cv2\n",
    "import sys\n",
    "import os\n",
    "import json\n",
    "import pprint\n",
    "import numpy as np\n",
    "import Image_detection.utilities as utilities\n",
    "\n",
    "# Add path to the system\n",
    "sys.path.append('./Image_detection/ChartDete')\n",
    "\n",
    "# Import specific functions from mmdet and util\n",
    "from mmdet.apis import init_detector, inference_detector\n",
    "\n",
    "from IPython.display import Image, display\n",
    "\n",
    "# Google Generative AI library\n",
    "import google.generativeai as genai\n",
    "\n",
    "# skimage and temporary file handling libraries\n",
    "import skimage.io as io \n",
    "\n",
    "# Add path to the system for line detection\n",
    "sys.path.append('./Image_detection/Line_detection')\n",
    "\n",
    "# Import specific functions for line detection\n",
    "from Image_detection.Line_detection.utils import process_image, save_and_plot_data\n",
    "from Image_detection.Line_detection.BB_Inference import LineInference\n",
    "#from Image_detection.Line_detection.mmdetection.mmdet.apis import init_detector, inference_detector\n",
    "\n",
    "# Import matplotlib for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from AI.Gemini.CEImage import GeminiImageProcessor\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configuration of the API from Google"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the API key in the environment variables\n",
    "os.environ[\"GEMINI_API_KEY\"] = 'AIzaSyDFuwrnPunjaEG5WlzjycQ75km-w2MFsgc'\n",
    "\n",
    "# Retrieve the API key from the environment variables\n",
    "api_key = os.environ[\"GEMINI_API_KEY\"]\n",
    "\n",
    "# Configure the Google Generative AI library with the API key\n",
    "genai.configure(api_key=api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define paths:\n",
    " (Argparse produces errors in Jupyter notebooks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths to directories\n",
    "input_dir = './data/images'\n",
    "output_dir = './data/CE_output'\n",
    "\n",
    "# Define paths to weights and configuration files\n",
    "weights_path = './Image_detection/weights/work_dirs/cascade_rcnn_swin-t_fpn_LGF_VCE_PCE_coco_focalsmoothloss/checkpoint.pth'\n",
    "config_path = './Image_detection/weights/work_dirs/cascade_rcnn_swin-t_fpn_LGF_VCE_PCE_coco_focalsmoothloss/cascade_rcnn_swin-t_fpn_LGF_VCE_PCE_coco_focalsmoothloss.py'\n",
    "\n",
    "# Manually define the image name\n",
    "image_name = 'sample_image.png'\n",
    "\n",
    "# Manually define the image path\n",
    "image_path = './data/DemoImages/image6.png'\n",
    "\n",
    "# Define the output path using output_dir and the image name\n",
    "output_path = os.path.join(output_dir, f\"{image_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Section for Element Detection in a Chart\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize and Run the ChartDete Model\n",
    "\n",
    "In this section, we will initialize the ChartDete model with the specified configuration and weights, and run inference on the selected image. The results will be processed to extract Regions of Interest (ROIs) and filter them based on confidence levels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model with the given configuration and weights\n",
    "model = init_detector(config_path, weights_path, device='cpu')\n",
    "\n",
    "# Run inference on the specified image\n",
    "result = inference_detector(model, image_path)\n",
    "\n",
    "print(f'Inference completed for {image_name}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We separate the output of the inference and We make a selection of the most probable ROIs for each case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract ROIs from the result\n",
    "X_label_ROI, Y_label_ROI, plot_area_ROI, _, x_numbers_ROI, y_numbers_ROI, title_ROI, x_ticks_ROI, y_ticks_ROI, legend_points_ROI, legend_text_ROI, _, legend_area_ROI, _, _, y_area_ROI, x_area_ROI, _ = result\n",
    "\n",
    "# Filter ROIs by confidence and define colors for each group\n",
    "rois_dict = {\n",
    "    'x_numbers': {'rois': utilities.filter_rois_by_confidence(x_numbers_ROI), 'color': (0, 255, 0)},\n",
    "    'y_numbers': {'rois': utilities.filter_rois_by_confidence(y_numbers_ROI), 'color': (255, 0, 0)},\n",
    "    'x_label': {'rois': utilities.filter_rois_by_confidence(X_label_ROI), 'color': (0, 0, 255)},\n",
    "    'y_label': {'rois': utilities.filter_rois_by_confidence(Y_label_ROI), 'color': (255, 255, 0)},\n",
    "    'title': {'rois': utilities.filter_rois_by_confidence(title_ROI), 'color': (255, 0, 255)},\n",
    "    'x_ticks': {'rois': utilities.filter_rois_by_confidence(x_ticks_ROI), 'color': (0, 255, 255)},\n",
    "    'y_ticks': {'rois': utilities.filter_rois_by_confidence(y_ticks_ROI), 'color': (128, 0, 128)},\n",
    "    'legend_points': {'rois': utilities.filter_rois_by_confidence(legend_points_ROI), 'color': (128, 128, 0)},\n",
    "    'legend_text': {'rois': utilities.filter_rois_by_confidence(legend_text_ROI), 'color': (0, 128, 128)},\n",
    "    'legend_area': {'rois': utilities.filter_rois_by_confidence(legend_area_ROI), 'color': (128, 128, 128)},\n",
    "    'y_area': {'rois': utilities.filter_rois_by_confidence(y_area_ROI), 'color': (64, 64, 64)},\n",
    "    'x_area': {'rois': utilities.filter_rois_by_confidence(x_area_ROI), 'color': (192, 192, 192)},\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process the image with the Gemini API and obtain the result in JSON format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize GeminiImageProcessor\n",
    "gemini_processor = GeminiImageProcessor(debug=False)\n",
    "\n",
    "\n",
    "#result_json = utilities.process_image_with_gemini(image_path, output_path)\n",
    "\n",
    "result_json = gemini_processor.process_image_with_gemini(image_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we plot the result up to this point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw and save ROIs on the image\n",
    "image = utilities.draw_and_save_rois(image_path, rois_dict, thickness=2)\n",
    "\n",
    "# Encode the image to display it\n",
    "_, buffer = cv2.imencode('.png', image)\n",
    "display(Image(data=buffer))\n",
    "\n",
    "# Pretty print the JSON result\n",
    "pprint.pprint(result_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Process to Calculate the Scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate midpoints for both x and y numbers\n",
    "x_midpoints = utilities.calculate_midpoints(x_numbers_ROI, axis='x')\n",
    "y_midpoints = utilities.calculate_midpoints(y_numbers_ROI, axis='y')\n",
    "\n",
    "# Sort midpoints\n",
    "x_midpoints.sort()\n",
    "y_midpoints.sort(reverse=True)\n",
    "\n",
    "# Extract x_numbers and y_numbers from the JSON dictionary\n",
    "x_numb = result_json['x_numbers']\n",
    "y_numb = result_json['y_numbers']\n",
    "\n",
    "# Map x_numbers to x_midpoints\n",
    "x_midpoints_dict = {x: float(midpoint) for x, midpoint in zip(x_numb, x_midpoints)}\n",
    "\n",
    "# Map y_numbers to y_midpoints\n",
    "y_midpoints_dict = {y: float(midpoint) for y, midpoint in zip(y_numb, y_midpoints)}\n",
    "\n",
    "# Calculate scales and average scale for x-axis\n",
    "x_scales, x_average_scale = utilities.calculate_scale(x_midpoints_dict)\n",
    "\n",
    "# Calculate scales and average scale for y-axis\n",
    "y_scales, y_average_scale = utilities.calculate_scale(y_midpoints_dict)\n",
    "try:\n",
    "    # Calculate the origin positions for both x and y axes\n",
    "    x_origin, y_origin = utilities.get_zero_or_min_position(x_midpoints_dict, y_midpoints_dict)\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred while calculating the origin positions: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw lines for both x and y midpoints\n",
    "image_with_lines = utilities.draw_lines(image.copy(), x_midpoints, axis='x', thickness=2, origin=x_origin)\n",
    "image_with_lines = utilities.draw_lines(image_with_lines, y_midpoints, axis='y', thickness=2, origin=y_origin)\n",
    "\n",
    "# Display the image with the lines\n",
    "_, buffer = cv2.imencode('.png', image_with_lines)\n",
    "display(Image(data=buffer))\n",
    "\n",
    "# Print the resulting dictionaries\n",
    "pprint.pprint(x_midpoints_dict)\n",
    "print()\n",
    "pprint.pprint(y_midpoints_dict)\n",
    "print()\n",
    "print(\"Calculated scales between consecutive points (x-axis):\")\n",
    "print(x_scales)\n",
    "print()\n",
    "print(\"Average scale for x-axis:\")\n",
    "print(x_average_scale)\n",
    "print()\n",
    "print(\"Calculated scales between consecutive points (y-axis):\")\n",
    "print(y_scales)\n",
    "print()\n",
    "print(\"Average scale for y-axis:\")\n",
    "print(y_average_scale)\n",
    "print()\n",
    "print(f\"Origin position in x_midpoints_dict: {x_origin}, \\nOrigin position in y_midpoints_dict: {y_origin}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have what is necessary to rescale the required dataset. But first, we must perform inference on the image to obtain the line datapoints."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section for Line Detection in a Chart"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create an instance of LineInference with specified configuration and checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference = LineInference(config=\"./Image_detection/Line_detection/config.py\", ckpt=\"./Image_detection/weights/weights.pth\", device=\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process the image and obtain the line data series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "line_dataseries = process_image(inference,image_path,mask_kp_sample_interval=10 ,inter_type='linear',eliminate_duplicates=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rescale the line data series using the calculated scales and origins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "line_dataseries_escal = utilities.rescale_line_dataseries(\n",
    "    x_average_scale, y_average_scale, x_origin, y_origin,\n",
    "    x_midpoints_dict, y_midpoints_dict, line_dataseries\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guarda y grafica la serie de datos\n",
    "#save_and_plot_data(line_dataseries_escal, image_path)\n",
    "\n",
    "\n",
    "# Display the example image and the plot side by side\n",
    "fig, axes = plt.subplots(1, 2, figsize=(20, 10))\n",
    "\n",
    "# Plot the rescaled line data series\n",
    "axes[0].set_title(result_json.get('title', 'Line Data Series'))\n",
    "axes[0].set_xlabel(result_json.get('x_label', 'X-axis'))\n",
    "axes[0].set_ylabel(result_json.get('y_label', 'Y-axis'))\n",
    "for series in line_dataseries_escal:\n",
    "    x_values = [point[0] for point in series]\n",
    "    y_values = [point[1] for point in series]\n",
    "    axes[0].plot(x_values, y_values)\n",
    "if 'legend' in result_json:\n",
    "    axes[0].legend(result_json['legend'])\n",
    "\n",
    "# Display the example image\n",
    "example_image = cv2.imread(image_path)\n",
    "example_image_rgb = cv2.cvtColor(example_image, cv2.COLOR_BGR2RGB)\n",
    "axes[1].imshow(example_image_rgb)\n",
    "axes[1].set_title('Example Image')\n",
    "axes[1].axis('off')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CONTINUAR CON EL RESTO DE APARTADOS."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hacemos la curva más smooth. **ESTO NO SE ESTÁ APLICANDO AL RESULTADO FINAL**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import savgol_filter\n",
    "from scipy.interpolate import UnivariateSpline\n",
    "\n",
    "def smooth_line_data(line_dataseries, method=0, window_size=1):\n",
    "    line_dataseries_smooth = []\n",
    "    for series in line_dataseries:\n",
    "        x_values = np.array([point[0] for point in series])\n",
    "        y_values = np.array([point[1] for point in series])\n",
    "\n",
    "        if method == 0:  # Savitzky-Golay filter\n",
    "            if len(x_values) > 3:  # Ensure there are enough points to apply Savitzky-Golay filter\n",
    "                y_smooth = savgol_filter(y_values, window_length=window_size, polyorder=2)\n",
    "                line_dataseries_smooth.append(list(zip(x_values, y_smooth)))\n",
    "            else:\n",
    "                line_dataseries_smooth.append(series)\n",
    "        elif method == 1:  # Moving average filter\n",
    "            if len(x_values) > 3:  # Ensure there are enough points to create a spline\n",
    "                y_smooth = np.convolve(y_values, np.ones(window_size) / window_size, mode='valid')\n",
    "                x_smooth = x_values[:len(y_smooth)]\n",
    "                line_dataseries_smooth.append(list(zip(x_smooth, y_smooth)))\n",
    "            else:\n",
    "                line_dataseries_smooth.append(series)\n",
    "        elif method == 2:  # Spline interpolation\n",
    "            if len(x_values) > 3:  # Ensure there are enough points to create a spline\n",
    "                spline = UnivariateSpline(x_values, y_values)\n",
    "                y_smooth = spline(x_values)\n",
    "                line_dataseries_smooth.append(list(zip(x_values, y_smooth)))\n",
    "            else:\n",
    "                line_dataseries_smooth.append(series)\n",
    "    return line_dataseries_smooth\n",
    "# Smooth the line data series\n",
    "line_dataseries_smooth = smooth_line_data(line_dataseries_escal, method=0, window_size=60)\n",
    "\n",
    "\n",
    "# Plot the original line data series in red\n",
    "for series in line_dataseries_escal:\n",
    "    x_values = [point[0] for point in series]\n",
    "    print(np.std(x_values))\n",
    "    y_values = [point[1] for point in series]\n",
    "    plt.plot(x_values, y_values, 'r')\n",
    "\n",
    "# Plot the smoothed line data series in green\n",
    "for series in line_dataseries_smooth:\n",
    "    x_values = [point[0] for point in series]\n",
    "    y_values = [point[1] for point in series]\n",
    "    plt.plot(x_values, y_values, 'g')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the rescaled line data series with legend\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.title(result_json.get('title', 'Line Data Series'))\n",
    "plt.xlabel(result_json.get('x_label', 'X-axis'))\n",
    "plt.ylabel(result_json.get('y_label', 'Y-axis'))\n",
    "\n",
    "# Plot each series and add legend\n",
    "for i, series in enumerate(line_dataseries_escal):\n",
    "    x_values = [point[0] for point in series]\n",
    "    y_values = [point[1] for point in series]\n",
    "    if i < len(result_json['lines']):\n",
    "        line_info = result_json['lines'][i]\n",
    "    else:\n",
    "        print(f\"Index {i} is out of range for the list 'lines' with length {len(result_json['lines'])}\")\n",
    "    color = 'blue' if line_info['line_type'] == 'compression' else 'red'\n",
    "    plt.plot(x_values, y_values, label=f\"{line_info['legend_label']} ({line_info['line_type']})\", color=color)\n",
    "\n",
    "# Add legend to the plot\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\"\"\"\n",
    "# Plot each series and add legend\n",
    "for i, series in enumerate(line_dataseries_smooth):\n",
    "    x_values = [point[0] for point in series]\n",
    "    y_values = [point[1] for point in series]\n",
    "    plt.plot(x_values, y_values, label=f'Linea {i+1}')\n",
    "\n",
    "# Add legend to the plot\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Voy a intentar hacer una llamada a la API de gemeni para que me filtre los puntos evidentes que no forman parte de la línea."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# He realizado promps en "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Esoy intentando aplicar la aproximación cercano y luego comprobar aqullos puntos que están muy lejos de mi spline para eliminarlos y despues volver a hacer un spline y asi hacer el preprocesado de lso datos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# También estoy intentando aplicar al prompt que ya he creado que haga la clasificación de la leyenda con las líneas. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cicproject",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
